# AI4I Predictive Maintenance ğŸ”§

> Vorhersage von MaschinenausfÃ¤llen mit kÃ¼nstlicher Intelligenz

## Was macht dieses Projekt?

Dieses Tool analysiert Sensordaten von Industriemaschinen und sagt vorher, wann sie wahrscheinlich ausfallen werden. So kÃ¶nnen Sie:

- **AusfÃ¤lle vermeiden** bevor sie passieren
- **Wartungskosten senken** durch bessere Planung  
- **Produktion optimieren** mit weniger ungeplanten Stopps
- **Geld sparen** durch prÃ¤ventive statt reaktive Wartung

## Quick Start ğŸš€

### 1. Installation

```bash
# Repository herunterladen
git clone https://github.com/prennerm/AI4I-Predictive-Maintenance.git
cd AI4I-Predictive-Maintenance

# Python-Pakete installieren
pip install -r requirements.txt
```

### 2. Erstes Modell trainieren

```bash
# VollstÃ¤ndiges Training mit Standardeinstellungen
python scripts/train_model.py

# Schneller Test (nur fÃ¼r Ausprobieren)
python scripts/train_model.py --quick-run
```

### 3. Vorhersagen machen

```bash
# Einzelne Vorhersage (Beispielwerte)
python scripts/predict.py --model models/best_model/ --input "300,310,1500,40,120"

# CSV-Datei mit mehreren Maschinen
python scripts/predict.py --model models/best_model/ --input your_data.csv --batch
```

### 4. Report erstellen

```bash
# Business-Report fÃ¼r Management
python scripts/generate_report.py --type executive --models models/

# Technischer Report
python scripts/generate_report.py --type technical --models models/
```

## Wie verwende ich eigene Daten? ğŸ“Š

### Datenformat

Ihre CSV-Datei sollte diese Spalten enthalten:

```csv
Air temperature [K],Process temperature [K],Rotational speed [rpm],Torque [Nm],Tool wear [min],Machine failure
300.1,309.2,1551,42.8,0,0
298.2,308.6,1408,46.3,3,0
...
```

- **Machine failure**: 0 = Normal, 1 = Ausfall (nur fÃ¼r Training nÃ¶tig)
- **Andere Spalten**: Sensormesswerte Ihrer Maschinen

### Eigene Daten verwenden

```bash
# 1. Ihre Daten ins data/raw/ Verzeichnis kopieren
cp ihre_daten.csv data/raw/

# 2. Modell mit Ihren Daten trainieren
python scripts/train_model.py --data data/raw/ihre_daten.csv

# 3. Vorhersagen fÃ¼r neue Daten
python scripts/predict.py --model models/best_model/ --input neue_daten.csv
```

## Verstehe die Ergebnisse ğŸ¯

### Vorhersage-Output

```json
{
  "prediction": 1,              // 0 = OK, 1 = Ausfall erwartet
  "probability": 0.85,          // 85% Ausfallwahrscheinlichkeit  
  "risk_level": "HIGH",         // LOW/MEDIUM/HIGH/CRITICAL
  "recommended_action": "Schedule maintenance within 48 hours",
  "confidence": 0.92            // Wie sicher ist das Modell
}
```

### Risk Levels erklÃ¤rt

- ğŸŸ¢ **LOW (0-30%)**: Weiterlaufen lassen
- ğŸŸ¡ **MEDIUM (30-60%)**: Wartung innerhalb 1 Woche planen
- ğŸŸ  **HIGH (60-80%)**: Wartung innerhalb 48h einplanen
- ğŸ”´ **CRITICAL (80%+)**: SOFORT warten - Maschine stoppen!

## HÃ¤ufige AnwendungsfÃ¤lle ğŸ’¼

### TÃ¤gliche Ãœberwachung

```bash
# Alle Maschinen tÃ¤glich prÃ¼fen
python scripts/predict.py --model models/best_model/ --input daily_readings.csv --business-report
```

### WÃ¶chentliche Management-Reports

```bash
# Automatischer Wochenreport
python scripts/generate_report.py --type executive --models models/ --format html
```

### API fÃ¼r andere Systeme

```bash
# REST API starten (Port 8080)
python scripts/predict.py --model models/best_model/ --api-mode --port 8080

# Dann HTTP POST an: http://localhost:8080/predict
# mit JSON: {"input": [300, 310, 1500, 40, 120]}
```

## Testen & Debugging ğŸ”

### Funktioniert alles?

```bash
# Schneller Funktionstest
python scripts/train_model.py --quick-run --no-hyperopt

# Sollte ohne Fehler durchlaufen und Modelle erstellen
```

### HÃ¤ufige Probleme & LÃ¶sungen

#### Problem: "ModuleNotFoundError"
```bash
# LÃ¶sung: Pakete installieren
pip install -r requirements.txt

# Oder spezifisches Paket
pip install pandas scikit-learn xgboost
```

#### Problem: "FileNotFoundError"
```bash
# Daten existieren?
ls data/raw/

# Modell existiert?
ls models/

# LÃ¶sung: Erst trainieren, dann vorhersagen
python scripts/train_model.py
```

#### Problem: Schlechte Vorhersagen
```bash
# Mehr Daten verwenden
python scripts/train_model.py --data data/raw/mehr_daten.csv

# Andere Modelle probieren
python scripts/train_model.py --models random_forest xgboost svm

# Performance prÃ¼fen
python scripts/evaluate_model.py --model-dir models/ --compare-all
```

### Debug-Modus aktivieren

```bash
# AusfÃ¼hrliche Logs fÃ¼r Problemdiagnose
python scripts/train_model.py --log-level DEBUG

# Logs finden Sie in: logs/
```

### Performance prÃ¼fen

```bash
# Detaillierte Modell-Evaluation
python scripts/evaluate_model.py --model-dir models/ --business-analysis

# Ergebnisse in: reports/evaluation/
```

## Erweiterte Nutzung âš™ï¸

### Konfigurationsdatei verwenden

Erstellen Sie `config.yaml`:

```yaml
data:
  test_size: 0.2
  preprocessing:
    scale_features: true

training:
  hyperparameter_optimization:
    enabled: true
    n_trials: 50

models:
  traditional:
    random_forest:
      n_estimators: [100, 200]
```

Dann verwenden:
```bash
python scripts/train_model.py --config config.yaml
```

### Batch-Verarbeitung

```bash
# Viele Dateien auf einmal
for file in data/raw/*.csv; do
    python scripts/predict.py --model models/best_model/ --input "$file" --output "predictions/$(basename $file .csv)_predictions.json"
done
```

### Automatisierung (Cron)

```bash
# TÃ¤glich um 6 Uhr neue Vorhersagen
0 6 * * * cd /pfad/zum/projekt && python scripts/predict.py --model models/best_model/ --input data/daily.csv --output reports/daily_predictions.json

# WÃ¶chentlich Modell neu trainieren  
0 2 * * 1 cd /pfad/zum/projekt && python scripts/train_model.py --data data/raw/weekly_data.csv
```

## Tipps fÃ¼r bessere Ergebnisse ğŸ’¡

### DatenqualitÃ¤t verbessern

1. **Mehr Daten sammeln** - Je mehr, desto besser
2. **Ausgewogene Daten** - Sowohl normale als auch Ausfall-Beispiele
3. **Aktuelle Daten** - RegelmÃ¤ÃŸig neue Daten hinzufÃ¼gen
4. **VollstÃ¤ndige Daten** - Wenige fehlende Werte

### Modell optimieren

```bash
# Verschiedene Feature-Sets probieren
python scripts/train_model.py --feature-set basic      # Weniger Features
python scripts/train_model.py --feature-set extended   # Standard
python scripts/train_model.py --feature-set comprehensive  # Alle Features

# Hyperparameter-Optimierung
python scripts/train_model.py --models xgboost --config hyperopt_config.yaml
```

### Business-Integration

1. **Schrittweise einfÃ¼hren** - Erst parallel zu bestehenden Prozessen
2. **Teams schulen** - Wartungsteams Ã¼ber neue Prozesse informieren
3. **KPIs messen** - Erfolg quantifizieren (AusfÃ¤lle, Kosten, Uptime)
4. **Feedback sammeln** - Kontinuierliche Verbesserung

## Projektstruktur verstehen ğŸ“

```
AI4I/
â”œâ”€â”€ scripts/           # Die 4 Hauptprogramme
â”‚   â”œâ”€â”€ train_model.py       # Modelle trainieren
â”‚   â”œâ”€â”€ evaluate_model.py    # Performance bewerten  
â”‚   â”œâ”€â”€ predict.py           # Vorhersagen machen
â”‚   â””â”€â”€ generate_report.py   # Reports erstellen
â”œâ”€â”€ src/               # Interner Code (nicht direkt verwenden)
â”œâ”€â”€ data/              # Ihre Daten
â”‚   â”œâ”€â”€ raw/                 # Original CSV-Dateien
â”‚   â””â”€â”€ processed/           # Verarbeitete Daten
â”œâ”€â”€ models/            # Trainierte Modelle
â”œâ”€â”€ reports/           # Generierte Reports
â””â”€â”€ logs/              # Debug-Informationen
```

**Faustregel**: Sie arbeiten hauptsÃ¤chlich mit den 4 Scripts in `scripts/`!

## Support & Hilfe ğŸ†˜

### Dokumentation

- **Technische Details**: Siehe `architecture.md`
- **API-Referenz**: Docstrings in den Python-Dateien
- **Beispiele**: Siehe Kommentare in den Scripts

### Fehlerbehebung

1. **Logs prÃ¼fen**: `logs/` Verzeichnis
2. **Debug-Modus**: `--log-level DEBUG` verwenden
3. **Step-by-step**: Ein Script nach dem anderen testen
4. **Clean start**: `models/` und `reports/` lÃ¶schen, neu anfangen

### Typische Workflows

#### Erstmaliger Nutzer
```bash
1. pip install -r requirements.txt
2. python scripts/train_model.py --quick-run
3. python scripts/predict.py --model models/best_model/ --input "300,310,1500,40,120"
4. python scripts/generate_report.py --type executive --models models/
```

#### Produktive Nutzung
```bash
1. python scripts/train_model.py --data data/raw/production_data.csv
2. python scripts/evaluate_model.py --model-dir models/ --business-analysis
3. python scripts/predict.py --model models/best_model/ --input daily_sensors.csv --business-report
4. python scripts/generate_report.py --type operational --predictions predictions.json
```

## Was als nÃ¤chstes? ğŸ¯

1. **Experimentieren**: Probieren Sie verschiedene Einstellungen aus
2. **Integrieren**: Verbinden Sie mit Ihren bestehenden Systemen
3. **Skalieren**: Erweitern Sie auf mehr Maschinen/Standorte
4. **Optimieren**: Nutzen Sie die Reports zur kontinuierlichen Verbesserung

---

ğŸš€ **Viel Erfolg bei der Vorhersage von MaschinenausfÃ¤llen!**

*Bei Fragen oder Problemen: Schauen Sie in die Logs (`logs/`) oder aktivieren Sie den Debug-Modus mit `--log-level DEBUG`*
